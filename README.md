
üìã Project Overview
Customer churn ‚Äî the phenomenon of customers discontinuing their relationship with a business ‚Äî is one of the most costly problems in retail banking. Acquiring a new customer costs five to seven times more than retaining an existing one, making early identification of at-risk customers a top strategic priority.

This project builds a complete, end-to-end machine learning pipeline to predict whether a bank customer is likely to leave, using a dataset of 10,000 European bank customers. The final deliverable is not just a notebook but a modular, importable Python class that can score new customer batches without retraining.

Central challenge: The target variable is heavily imbalanced (~80% stayed, ~20% exited). A naive model that always predicts "stayed" would achieve 80% accuracy ‚Äî while being completely useless. This project demonstrates how to correctly address that problem using SMOTE, and how to evaluate models using the right metrics.

üóÇÔ∏è Complete Project Structure
text
bank-customer-churn/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Customer-Churn-Records.csv       # Original Kaggle data (10,000 √ó 18)
‚îÇ   ‚îú‚îÄ‚îÄ processed/                            # Cleaned & engineered datasets
‚îÇ   ‚îî‚îÄ‚îÄ exports/
‚îÇ       ‚îî‚îÄ‚îÄ churn_tableau_export.csv          # For Tableau dashboard
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                                 # 7 sequential notebooks
‚îÇ   ‚îú‚îÄ‚îÄ N1_data_upload.ipynb                  # Load data, first look, data dictionary
‚îÇ   ‚îú‚îÄ‚îÄ N2_ExploratoryDataAnalysis.ipynb      # EDA: distributions, correlations, leakage
‚îÇ   ‚îú‚îÄ‚îÄ N3_data_cleaning.ipynb                # Drop identifiers, handle leakage, outliers
‚îÇ   ‚îú‚îÄ‚îÄ N4_data_engineering.ipynb             # Split ‚Üí encode ‚Üí scale (CustomScaler)
‚îÇ   ‚îú‚îÄ‚îÄ N5_Model_Train_Test_Selection.ipynb   # SMOTE ‚Üí train 6 models ‚Üí compare metrics
‚îÇ   ‚îú‚îÄ‚îÄ N6_Model_Saving.ipynb                  # Retrain on full data, save artifacts
‚îÇ   ‚îî‚îÄ‚îÄ N7_BankChurn_Module.ipynb              # Demo the production inference module
‚îÇ
‚îú‚îÄ‚îÄ artifacts/                                 # Generated by running notebooks
‚îÇ   ‚îú‚îÄ‚îÄ model_file.pkl                         # Trained best model (Random Forest)
‚îÇ   ‚îî‚îÄ‚îÄ Scaler_file.pkl                         # Fitted CustomScaler
‚îÇ
‚îú‚îÄ‚îÄ BankChurn_Module.py                        # Production inference class (import-ready)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
üìä Dataset & Data Dictionary
Source: Bank Customer Churn Dataset ‚Äî Kaggle
Shape: 10,000 rows √ó 18 columns
Target variable: Exited (1 = churned, 0 = stayed)

Column	Type	Description	Used in Model?
RowNumber	Integer	Sequential row index	‚ùå Dropped
CustomerId	Integer	Unique customer identifier	‚ùå Dropped
Surname	String	Customer last name	‚ùå Dropped
CreditScore	Integer	Credit score (300‚Äì850). Higher = better creditworthiness.	‚úÖ Yes
Geography	String	Country: France, Germany, or Spain	‚úÖ Encoded
Gender	String	Male or Female	‚úÖ Encoded
Age	Integer	Customer age in years	‚úÖ Yes
Tenure	Integer	Years as a bank customer (0‚Äì10)	‚úÖ Yes
Balance	Float	Current account balance in Euros	‚úÖ Yes
NumOfProducts	Integer	Number of bank products held (1‚Äì4)	‚úÖ Yes
HasCrCard	Binary (0/1)	Has a credit card? 1 = Yes	‚úÖ Yes
IsActiveMember	Binary (0/1)	Considered an active member? 1 = Yes	‚úÖ Yes
EstimatedSalary	Float	Estimated annual salary in Euros	‚úÖ Yes
Exited	Binary	TARGET: 1 = left the bank	üéØ Target
Complain	Binary	Filed a complaint? ‚Äî ‚ö†Ô∏è DROPPED (leakage)	‚ùå Dropped
Satisfaction Score	Integer	Customer satisfaction rating (1‚Äì5)	‚úÖ Yes
Card Type	String	DIAMOND / GOLD / SILVER / PLATINUM	‚úÖ Encoded
Point Earned	Integer	Reward points accumulated	‚úÖ Yes
Critical Note: Complain has a 0.99 Pearson correlation with Exited ‚Äî they are 99.7% identical. Including it would constitute target leakage: the model would learn a near-perfect shortcut that only exists in historical data, not in real-world deployment.

üî¨ Methodology: The Complete Pipeline
The Problem with Imbalanced Data
text
Stayed (0):  7,963 customers  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  79.6%
Exited (1):  2,037 customers  ‚ñà‚ñà‚ñà‚ñà‚ñà                      20.4%
A model predicting "stayed" for everyone would be 79.6% accurate ‚Äî but useless. This project addresses imbalance using SMOTE (Synthetic Minority Oversampling Technique).

How SMOTE Works
Instead of simply duplicating existing minority samples, SMOTE creates new, synthetic data points by interpolating between a minority sample and its nearest neighbors in feature space. This gives the model novel examples to learn from, forcing it to build a more robust decision boundary.

Critical rule: SMOTE is applied only to the training set, after the train/test split. The test set remains as the original real distribution to provide an honest evaluation.

python
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)
# Before: {0: 6370, 1: 1630}
# After:  {0: 6370, 1: 6370}  ‚Üê balanced!
üß™ Pipeline Steps in Detail
Step 1 ‚Äî N1: Data Upload & First Look
python
# Load data, check shape, dtypes, nulls
df = pd.read_csv('data/raw/Customer-Churn-Records.csv')
print(f"Shape: {df.shape}")          # (10000, 18)
print(df.isnull().sum())             # No missing values
print(df['Exited'].value_counts(normalize=True))  # 80% stayed, 20% exited
Step 2 ‚Äî N2: Exploratory Data Analysis
Key questions answered:

What is the overall churn rate? (20.4%)

How does churn vary by geography, gender, age, and number of products?

Are there correlations between numerical features?

Is there data leakage? (Yes ‚Äî Complain is 99% correlated with Exited)

Key visualizations:

Churn rate by Geography: Germany ~32% vs France/Spain ~16%

Age distribution: Churners have higher median age (40-60)

Correlation heatmap showing Complain leakage

Step 3 ‚Äî N3: Data Cleaning
python
# Drop identifier columns (no predictive value)
df_clean = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])

# Drop Complain (data leakage)
df_clean = df_clean.drop(columns=['Complain'])

# Check for outliers (not removed, but noted)
for col in ['CreditScore', 'Age', 'Balance']:
    # IQR method to identify outliers
    print(f"{col}: {len(outliers)} outliers")
Step 4 ‚Äî N4: Feature Engineering
The most important rule: Split BEFORE fitting any transformers!

python
# Train/test split FIRST
X = df_clean.drop(columns=['Exited'])
y = df_clean['Exited']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# One-hot encode categorical features
cat_cols = ['Geography', 'Gender', 'Card Type']
X_train = pd.get_dummies(X_train, columns=cat_cols, drop_first=True)
X_test = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)
X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

# Scale numerical features (but NOT binary flags!)
num_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',
            'EstimatedSalary', 'Point Earned', 'Satisfaction Score']
# HasCrCard and IsActiveMember remain as 0/1
CustomScaler Implementation:

python
class CustomScaler:
    """Wraps StandardScaler to scale only numerical columns, not binary flags."""
    def __init__(self, num_cols):
        self.num_cols = num_cols
        self.scaler = StandardScaler()
    
    def fit(self, X):
        self.scaler.fit(X[self.num_cols])
        return self
    
    def transform(self, X):
        X_copy = X.copy()
        X_copy[self.num_cols] = self.scaler.transform(X_copy[self.num_cols])
        return X_copy
Step 5 ‚Äî N5: Model Training & Selection
Six algorithms compared:

Model	Accuracy	Precision	Recall	F1	ROC-AUC
Random Forest ‚≠ê	0.93	0.93	0.93	0.93	0.98
Gradient Boosting	0.92	0.92	0.92	0.92	0.97
Decision Tree	0.88	0.88	0.88	0.88	0.88
KNN	0.87	0.87	0.87	0.87	0.95
SVC	0.84	0.84	0.84	0.84	0.92
Logistic Regression	0.80	0.80	0.80	0.80	0.87
Why Random Forest won:

Highest F1 score and ROC-AUC

Robust to outliers

Built-in feature importance

Handles non-linear relationships well

Step 6 ‚Äî N6: Model Saving
python
import pickle

# Retrain on 100% of SMOTE-balanced data
best_model = RandomForestClassifier(n_estimators=100, random_state=42)
best_model.fit(X_train_res, y_train_res)  # SMOTE-balanced data

# Save model and scaler
with open('artifacts/model_file.pkl', 'wb') as f:
    pickle.dump(best_model, f)

with open('artifacts/Scaler_file.pkl', 'wb') as f:
    pickle.dump(scaler, f)
Step 7 ‚Äî N7: Production Module Demo
python
from BankChurn_Module import CustomerChurn

# Initialize with saved artifacts
churn_predictor = CustomerChurn(
    model_file='artifacts/model_file.pkl',
    scaler_file='artifacts/Scaler_file.pkl'
)

# Load and preprocess new customer data
churn_predictor.load_and_clean_data('new_customers.csv')

# Generate predictions
results = churn_predictor.predict_churn()
print(results[['CustomerId', 'Surname', 'Predicted_Exited']].head())
üí° Key Findings & Business Insights
Finding 1 ‚Äî Geography matters significantly
German customers churn at nearly twice the rate of French or Spanish customers (~32% vs ~16%). This suggests either competitive pressure or product-market fit issues specific to that region.

Finding 2 ‚Äî Age is the strongest individual predictor
Customers aged 40‚Äì60 are substantially more likely to churn. This may indicate a "switching window" where mid-career customers re-evaluate financial relationships as their wealth grows.

Finding 3 ‚Äî Number of products is a double-edged sword

Customers with 2 products: lowest churn rate

Customers with 3‚Äì4 products: highest churn rate (counterintuitive)
This suggests forced bundling may cause dissatisfaction.

Finding 4 ‚Äî Account balance and churn have a bimodal relationship
Both zero-balance customers (dormant/disengaged) and very high-balance customers (shopping competitors) show elevated churn.

Finding 5 ‚Äî Active membership is strongly protective
Customers flagged as "active members" churn at roughly half the rate of inactive members.

Feature Importance (Random Forest):

Age

NumOfProducts

IsActiveMember

Balance

Geography_Germany

üêç Using the CustomerChurn Module
The BankChurn_Module.py file provides a clean, reusable API for predictions:

python
from BankChurn_Module import CustomerChurn

# Initialize
churn_predictor = CustomerChurn(
    model_file='artifacts/model_file.pkl',
    scaler_file='artifacts/Scaler_file.pkl'
)

# Load new data (must match original schema, minus Exited)
churn_predictor.load_and_clean_data('new_customers.csv')

# Get predictions (returns DataFrame with 'Predicted_Exited' column)
predictions = churn_predictor.predict_churn()

# Check results
print(f"Predicted to churn: {predictions['Predicted_Exited'].sum()} "
      f"of {len(predictions)} customers")
What the class does automatically:

Drops non-predictive identifier columns (RowNumber, CustomerId, Surname)

Drops Complain (leakage variable)

Applies one-hot encoding to categorical fields

Scales numerical columns using the saved scaler

Returns original data with added Predicted_Exited column

üìä Tableau Dashboard: "Bank Churn Command Center"
A business-facing interactive dashboard for exploring churn patterns without code.

Worksheet Specifications
Sheet 1 ‚Äî Churn Rate by Geography (Bar/Map)

Shows Germany at ~32% vs France/Spain at ~16%

Sheet 2 ‚Äî Age Distribution: Churners vs. Stayers (Dual histogram)

Visualizes the 40-60 age risk window

Sheet 3 ‚Äî Churn Rate by Number of Products (Bar chart)

Reference line at overall average (20.4%)

Highlights 3-4 product anomaly

Sheet 4 ‚Äî Feature Importance (Horizontal bar)

Top 15 features from Random Forest

Sheet 5 ‚Äî Churn Probability Distribution (Histogram)

Shows customer risk segmentation

Export for Tableau
python
# In notebook
tableau_df = df_clean.copy()
tableau_df['Churn_Probability'] = best_model.predict_proba(X)[:, 1]
tableau_df.to_csv('data/exports/churn_tableau_export.csv', index=False)
üéØ Why NOT Accuracy? ‚Äî Evaluation Metrics Explained
Metric	Formula	Why it matters here
Precision	TP / (TP + FP)	Of all predicted churners, how many actually churned?
Recall	TP / (TP + FN)	Of all actual churners, how many did we catch? ‚Üê most important
F1-Score	Harmonic mean of P & R	Balance between precision and recall
ROC-AUC	Area under ROC curve	Overall separability ‚Äî model-threshold independent
In this business context, recall on the churn class is the priority metric. A false negative (missed churner) is costlier than a false positive (unnecessary retention offer to a loyal customer).

‚öôÔ∏è Installation & Quick Start
bash
# 1. Clone the repository
git clone https://github.com/alfredosaldana/P01_BankCustomerChurn_Module.git
cd bank-customer-churn

# 2. Install dependencies
pip install -r requirements.txt

# 3. Download the dataset from Kaggle and place in data/raw/
# https://www.kaggle.com/datasets/radheshyamkollipara/bank-customer-churn

# 4. Run notebooks in order: N1 ‚Üí N2 ‚Üí N3 ‚Üí N4 ‚Üí N5 ‚Üí N6 ‚Üí N7

# 5. Use the inference module on new data
python -c "from BankChurn_Module import CustomerChurn; \
           model = CustomerChurn('artifacts/model_file.pkl', 'artifacts/Scaler_file.pkl'); \
           model.load_and_clean_data('new_customers.csv'); \
           print(model.predict_churn().head())"
requirements.txt:

text
pandas>=1.5.0
numpy>=1.23.0
scikit-learn>=1.1.0
imbalanced-learn>=0.10.0
matplotlib>=3.6.0
seaborn>=0.12.0
plotly>=5.10.0
shap>=0.41.0
joblib>=1.2.0
‚ö†Ô∏è Limitations & Caveats
Educational dataset: This Kaggle dataset is simulated ‚Äî findings may not generalize to real bank data without revalidation.

Complain leakage: In a production system, the timing of complaints would determine if it's a valid predictor. Here, it's dropped.

Static snapshot: No transaction history or behavioral time-series features. Real churn models benefit from trend features (e.g., declining balance over 6 months).

SMOTE caveat: Synthetic samples are mathematically plausible but not real customers. Aggressive oversampling can cause overfitting.

Threshold selection: The default 0.5 threshold is not necessarily optimal. Tune based on business costs (false negative vs. false positive).

Geography scope: Only France, Germany, Spain. The model cannot be applied elsewhere without retraining.

Binary features not scaled: HasCrCard and IsActiveMember remain 0/1 ‚Äî intentional, but must be handled consistently.

üöÄ Next Steps & Future Work
SHAP explainability: Add SHAP values to explain individual predictions ‚Äî critical for regulatory and stakeholder acceptance

Hyperparameter tuning: Apply Optuna Bayesian optimization to the final model

REST API deployment: Wrap CustomerChurn in FastAPI for real-time scoring from a CRM

Model monitoring: Implement data drift detection with evidently to alert when retraining is needed

Time-series features: Enrich with rolling statistics if transaction-level data becomes available

Cost-sensitive learning: Explore class_weight and custom cost matrices as SMOTE alternatives

Animated churn trends: Use Plotly to show how churn evolves over time (if multi-year data)

üéì Skills Demonstrated
Component	Skill Demonstrated
EDA notebooks	Data intuition, visual communication
SMOTE + imbalanced learning	Handling real-world messy data
Train/test split discipline	ML best practices, preventing leakage
Multi-model comparison	Statistical reasoning, model evaluation
CustomScaler class	Software engineering for data science
Tableau dashboard	Business communication, BI tools

This README	Technical writing and documentation
üìÑ License
MIT License ‚Äî feel free to use, adapt, and share with attribution.
Dataset sourced from Kaggle under its respective terms of use.

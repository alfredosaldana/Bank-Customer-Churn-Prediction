{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customer Churn Prediction\n",
    "## Notebook 6 \u2014 Final Model Training and Saving\n",
    "\n",
    "**Goal:** Train the selected Random Forest model on the complete processed dataset and save it.\n",
    "\n",
    "### Why retrain on 100% of the data?\n",
    "\n",
    "In N5 we split the data 80/20 to get an honest performance estimate. Now that the model is selected, the standard practice is to retrain on all available data before deployment \u2014 more training data means better generalisation. Performance was already validated on the N5 test set.\n",
    "\n",
    "> Analogy: Like a student who sets aside practice questions to test themselves, but studies every question before the real exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv('data_processed.csv')\n",
    "print(f'Dataset loaded: {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')\n",
    "print('Features:', X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Should We Apply SMOTE When Training the Final Model?\n\n",
    "Short answer: **No.** Here is the reasoning:\n\n",
    "The purpose of SMOTE in N5 was to prevent the model from ignoring the minority class during *training*. But for the **final production model**, we want it calibrated to the **real-world class distribution** (\u224820% churn, \u224880% stay).\n\n",
    "If we SMOTE the final training data:\n",
    "- The model learns a 50/50 world that doesn't exist.\n",
    "- `predict_proba()` outputs will be poorly calibrated \u2014 it will overestimate churn probability for every customer.\n",
    "- Downstream decisions (retention budgets, alert thresholds) will be based on inflated probabilities.\n\n",
    "The better practice for the final model is to train on the **real, imbalanced data** and use the `class_weight='balanced'` parameter OR tune the decision threshold \u2014 not SMOTE.\n\n",
    "> **What we do here:** Train on all 10,000 real customers without resampling.\n",
    "> The model generalises better because it reflects the true proportion of churners in the real world.\n",
    "> Recall on the minority class stays reasonable because Random Forest is already relatively robust to mild imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train on the Full Dataset\n",
    "\n",
    "Key Random Forest parameters:\n",
    "- `n_estimators=100` \u2014 100 decision trees in the ensemble\n",
    "- `random_state=42` \u2014 reproducibility\n",
    "- `max_features='sqrt'` \u2014 each tree sees a random subset of features, reducing correlation between trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "print('Model trained on full dataset.')\n",
    "print(f'  Trees: {final_model.n_estimators}')\n",
    "print(f'  Features: {final_model.n_features_in_}')\n",
    "print(f'  Classes: {final_model.n_classes_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save with Pickle\n",
    "\n",
    "Pickle serialises any Python object to disk. This allows the model to be reloaded in any script \u2014 including the inference module in N7.\n",
    "\n",
    "```\n",
    "Save  \u2014 open('file.pkl', 'wb')  then  pickle.dump(object, file)\n",
    "Load  \u2014 open('file.pkl', 'rb')  then  pickle.load(file)\n",
    "```\n",
    "\n",
    "**Security note:** Only unpickle files from trusted sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_file.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "for path in ['model_file.pkl', 'Scaler_file.pkl']:\n",
    "    if os.path.exists(path):\n",
    "        kb = os.path.getsize(path) / 1024\n",
    "        print(f'  {path:<25s}  {kb:>8.1f} KB  saved')\n",
    "    else:\n",
    "        print(f'  WARNING: {path} not found \u2014 run N4 first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_file.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "sample = X.iloc[[0]]\n",
    "pred   = loaded_model.predict(sample)\n",
    "prob   = loaded_model.predict_proba(sample)\n",
    "\n",
    "label = 'Churned' if pred[0] == 1 else 'Stayed'\n",
    "print(f'Sample prediction : {pred[0]}  ({label})')\n",
    "print(f'Stay probability  : {prob[0][0]:.3f}')\n",
    "print(f'Churn probability : {prob[0][1]:.3f}')\n",
    "print('Model verified successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Artifact | File | Notes |\n",
    "|---|---|---|\n",
    "| Production model | `model_file.pkl` | Random Forest on 100% of data |\n",
    "| Scaler | `Scaler_file.pkl` | Fitted in N4 \u2014 same parameters as training |\n",
    "\n",
    "Both artifacts are required by the inference module in N7.\n",
    "\n",
    "Continue to **N7_BankChurn_Module** to see the full inference pipeline in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfe6 Bank Customer Churn Prediction\n",
    "## Notebook 7 \u2014 Production Inference Module\n",
    "\n",
    "**Goal:** Demonstrate the `CustomerChurn` class from `BankChurn_Module.py` \u2014 a clean, reusable Python module that encapsulates the entire inference pipeline.\n",
    "\n",
    "### Why package the inference pipeline into a class?\n",
    "\n",
    "When deploying a machine learning model in the real world (e.g., as an API, a scheduled job, or an embedded tool), you need a consistent, reproducible way to:\n",
    "1. Load the model and scaler.\n",
    "2. Accept raw input data.\n",
    "3. Apply the *exact same* preprocessing as during training.\n",
    "4. Return predictions in a human-readable format.\n",
    "\n",
    "Putting all of this in a well-documented class makes the code:\n",
    "- **Reusable** \u2014 import and use from any script or application.\n",
    "- **Maintainable** \u2014 one place to update if preprocessing logic changes.\n",
    "- **Testable** \u2014 each method can be independently unit-tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module we built (must be in the same directory or on the Python path)\n",
    "from BankChurn_Module import CustomerChurn\n",
    "\n",
    "print('BankChurn_Module imported successfully \u2713')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Module Architecture Overview\n",
    "\n",
    "```\n",
    "BankChurn_Module.py\n",
    "\u2502\n",
    "\u251c\u2500\u2500 class CustomScaler\n",
    "\u2502     \u251c\u2500\u2500 __init__()    \u2014 store columns list + StandardScaler\n",
    "\u2502     \u251c\u2500\u2500 fit()         \u2014 learn mean/std from training data\n",
    "\u2502     \u2514\u2500\u2500 transform()   \u2014 apply scaling, preserve column order\n",
    "\u2502\n",
    "\u2514\u2500\u2500 class CustomerChurn\n",
    "      \u251c\u2500\u2500 __init__()              \u2014 load model.pkl + scaler.pkl\n",
    "      \u251c\u2500\u2500 load_and_clean_data()   \u2014 read CSV \u2192 drop cols \u2192 scale \u2192 encode \u2192 reindex\n",
    "      \u2514\u2500\u2500 predict_churn()         \u2014 run model \u2192 attach predictions \u2192 return DataFrame\n",
    "```\n",
    "\n",
    "The design follows the **Single Responsibility Principle** \u2014 each method does exactly one thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiate the Model\n",
    "\n",
    "Creating a `CustomerChurn` object loads both the model and the scaler into memory.  \n",
    "This is done once and the object is then reused for all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate \u2014 loads model_file.pkl and Scaler_file.pkl\n",
    "churn_predictor = CustomerChurn(\n",
    "    model_file  = 'model_file.pkl',\n",
    "    scaler_file = 'Scaler_file.pkl'\n",
    ")\n",
    "\n",
    "print('Model type   :', type(churn_predictor.model_selected))\n",
    "print('Scaler type  :', type(churn_predictor.scaler_selected))\n",
    "print('Ready for inference \u2713')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess New Data\n",
    "\n",
    "`load_and_clean_data()` mirrors the training pipeline steps:\n",
    "1. Read raw CSV.\n",
    "2. Drop identifier/leakage columns.\n",
    "3. Scale numerical features using the **pre-fitted** scaler (transform only \u2014 no re-fitting).\n",
    "4. One-hot encode categorical features.\n",
    "5. Reindex to the model's expected feature order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo we use the original CSV (which contains 'Exited').\n",
    "# In production, the input CSV would be new customers WITHOUT the 'Exited' column.\n",
    "# The module will silently skip dropping 'Exited' if it's absent (errors='ignore').\n",
    "\n",
    "preprocessed_data = churn_predictor.load_and_clean_data('Customer-Churn-Records.csv')\n",
    "\n",
    "print(f'Preprocessed features shape: {preprocessed_data.shape}')\n",
    "print(f'Expected columns: {churn_predictor.FEATURE_COLUMNS}')\n",
    "print()\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = churn_predictor.predict_churn()\n",
    "\n",
    "print(f'Output DataFrame shape: {results.shape}')\n",
    "print(f'Columns: {results.columns.tolist()}')\n",
    "print()\n",
    "# Show a human-readable view: key identifiers + prediction\n",
    "display_cols = ['CustomerId', 'Surname', 'Geography', 'Gender', 'Age',\n",
    "                'Balance', 'NumOfProducts', 'IsActiveMember', 'Predicted_Exited']\n",
    "# Only include columns that exist in results\n",
    "display_cols = [c for c in display_cols if c in results.columns]\n",
    "results[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction distribution\n",
    "pred_counts = results['Predicted_Exited'].value_counts()\n",
    "print('Prediction distribution:')\n",
    "print(f'  Predicted to STAY   : {pred_counts.get(0, 0):,}  ({pred_counts.get(0, 0)/len(results)*100:.1f}%)')\n",
    "print(f'  Predicted to CHURN  : {pred_counts.get(1, 0):,}  ({pred_counts.get(1, 0)/len(results)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. \u26a0\ufe0f In-Sample Check (Not True Validation)\n\nSince our demo CSV includes the actual `Exited` column, we can run a sanity check.\n\n**Important caveat:** The final model in N6 was trained on ALL 10,000 rows of this same file. Comparing its predictions to the actual labels here is **in-sample evaluation** \u2014 we are measuring how well the model memorised its own training data, not how well it generalises.\n\n**True generalisation performance** was measured in N5 on the held-out 20% test set (real, unseen, imbalanced data). Those are the metrics to report.\n\nThis cell is included only as a deployment sanity check: if accuracy here is not near 100%, something is broken in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n\nif 'Exited' in results.columns:\n    acc = accuracy_score(results['Exited'], results['Predicted_Exited'])\n    print(f'In-sample accuracy (training data \u2014 NOT a generalisation metric): {acc:.4f}')\n    print('  \u2192 See N5 test-set metrics for true generalisation performance.')\n    print()\n    print(classification_report(results['Exited'], results['Predicted_Exited'],\n                                 target_names=['Stayed', 'Churned']))\nelse:\n    print('No actual labels available for comparison (production mode).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Predictions\n",
    "\n",
    "The output DataFrame can be saved to a CSV for downstream use \u2014 uploading to a CRM, scheduling retention campaigns, or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'churn_predictions_output.csv'\n",
    "results.to_csv(output_path, index=False)\n",
    "print(f'\u2705 Predictions saved to  {output_path}')\n",
    "print(f'   Rows: {len(results):,}  |  Columns: {len(results.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \u2705 Project Complete \u2014 End-to-End Summary\n",
    "\n",
    "| Notebook | Task | Key Output |\n",
    "|---|---|---|\n",
    "| N1 | Data upload & first look | Dataset shape, dtypes, data dictionary |\n",
    "| N2 | EDA | Distributions, correlations, leakage finding |\n",
    "| N3 | Data cleaning | `df_cleaned.csv` (14 cols, 10K rows) |\n",
    "| N4 | Feature engineering | `data_processed.csv`, `Scaler_file.pkl` |\n",
    "| N5 | Model training & selection | Random Forest selected |\n",
    "| N6 | Final model saving | `model_file.pkl` |\n",
    "| **N7** | **Inference module** | **`churn_predictions_output.csv`** |\n",
    "\n",
    "### Possible Next Steps\n",
    "- **Hyperparameter tuning** \u2014 `GridSearchCV` on `n_estimators`, `max_depth`, `min_samples_leaf`.\n",
    "- **SHAP values** \u2014 Explain individual predictions (\"why did customer X get flagged?\").\n",
    "- **Flask/FastAPI deployment** \u2014 Wrap `CustomerChurn` class in an HTTP endpoint.\n",
    "- **Monitoring** \u2014 Track prediction drift over time as new customer data arrives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}